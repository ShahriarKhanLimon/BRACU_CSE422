# -*- coding: utf-8 -*-
"""2_19101444_Md.ShahriarKhanLimon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g0QH0uoUEr-kE4ok2k-i0c4gwnGvMFSv
"""

from google.colab import drive
drive.mount('/content/drive')

import os
directory = "/content/drive/MyDrive/CSE422 lab"
os.chdir(directory)

import pandas as pd
df = pd.read_csv('wine.csv')
df

df.shape
df.columns
df.head()
df.sample()
print(df.shape)

df.isnull().sum()

df.info()

df['quality'].unique()

df['quality'] = df['quality'].map({'good':1, 'bad':0})
print(df[['quality']].head())

from sklearn.preprocessing import MinMaxScaler
scaling = []
for i in df:
  mx = max(df[i])
  mn = min(df[i])
  if mn<0 or mx>1:
    scaling.append(i)

scaler = MinMaxScaler()
for i in scaling:
  scaler.fit(df[[i]])
  df[i] = scaler.transform(df[[i]])

for_cor=df.corr()
import seaborn as sns
sns.heatmap(for_cor, cmap="cool")

from sklearn.model_selection import train_test_split
list_of_features=[]
for i in df:
  if i!="quality":
    list_of_features.append(i)
print(list_of_features)
x_data =  df[list_of_features]
y_data =  df['quality']
x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2,random_state=1)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
m1 = SVC(kernel="linear")

m1.fit(x_train, y_train)

y_pred1 = m1.predict(x_test)

score1 = accuracy_score(y_pred1, y_test)
score1

from sklearn.neural_network import MLPClassifier

m2 = MLPClassifier(hidden_layer_sizes=(10), activation="relu", max_iter=10000)
m2.fit(x_train, y_train)

y_pred2 = m2.predict(x_test)

score2 = accuracy_score(y_pred2, y_test)
score2

from sklearn.ensemble import RandomForestClassifier

m3 = RandomForestClassifier(n_estimators=100)
m3.fit(x_train, y_train)

y_pred3 = m3.predict(x_test)

score3 = accuracy_score(y_pred3, y_test)
score3

half = (df.columns.shape[0]-1)//2
half

from sklearn.decomposition import PCA 
pca = PCA(n_components=half)

principal_components = pca.fit_transform(x_data)
principal_components

pca.explained_variance_ratio_ # how much information we lost

sum(pca.explained_variance_ratio_)

principal_df = pd.DataFrame(data=principal_components, columns=["Principle Component 1", 'Principle Component 2',"Principle Component 3", 'Principle Component 4',"Principle Component 5"])

main_df=pd.concat([principal_df, df[["quality"]]], axis=1)

main_df.head()

x_data = main_df.drop("quality" , axis=1)
y_data = main_df["quality"]

x_train, x_test, y_train, y_test = train_test_split(x_data, 
                                                    y_data,
                                                    test_size = 0.2,
                                                    random_state=1)

from sklearn.svm import SVC

m1 = SVC(kernel="linear")

m1.fit(x_train, y_train)

y_pred1 = m1.predict(x_test)

score11 = accuracy_score(y_pred1, y_test)
score11

from sklearn.neural_network import MLPClassifier

m2 = MLPClassifier(hidden_layer_sizes=(10), activation="relu", max_iter=10000)
m2.fit(x_train, y_train)

y_pred2 = m2.predict(x_test)

score22 = accuracy_score(y_pred2, y_test)
score22

from sklearn.ensemble import RandomForestClassifier

m3 = RandomForestClassifier(n_estimators=100)
m3.fit(x_train, y_train)

y_pred3 = m3.predict(x_test)

score33 = accuracy_score(y_pred3, y_test)
score33

import numpy as np
import matplotlib.pyplot as plt
 
# set width of bar
barWidth = 0.20
fig = plt.subplots(figsize =(12, 8))
 
# set height of bar
svm = [score1, score11]
mlp = [score2, score22]
rfc = [score3, score33]
 
# Set position of bar on X axis
br1 = np.arange(len(svm))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
 
# Make the plot
plt.bar(br1, svm, color ='r', width = barWidth,
        edgecolor ='grey', label ='SVM')
plt.bar(br2, mlp, color ='g', width = barWidth,
        edgecolor ='grey', label ='MLP')
plt.bar(br3, rfc, color ='b', width = barWidth,
        edgecolor ='grey', label ='RFC')
 
# Adding Xticks
plt.ylabel('Score', fontweight ='bold', fontsize = 15)
plt.xticks([r + barWidth for r in range(len(svm))],
        ['Before-PCA', 'After-PCA'])
 
plt.legend()
plt.show()