# -*- coding: utf-8 -*-
"""2_19101444_Md.ShahriarKhanLimon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tTzYgb8ITMSPnhlXN5sDYji8FbNs4Jdo
"""

from google.colab import drive
drive.mount('/content/drive')

import os
directory = "/content/drive/MyDrive/CSE422 lab"
os.chdir(directory)

import pandas as pd
df = pd.read_csv('wine.csv')
df

df.shape
df.columns
df.head()
df.sample()
print(df.shape)

df.isnull().sum()

df.info()

df['quality'].unique()

df['quality'] = df['quality'].map({'good':1, 'bad':0})
print(df[['quality']].head())

from sklearn.preprocessing import MinMaxScaler
scaling = []
for i in df:
  mx = max(df[i])
  mn = min(df[i])
  if mn<0 or mx>1:
    scaling.append(i)

scaler = MinMaxScaler()
for i in scaling:
  scaler.fit(df[[i]])
  df[i] = scaler.transform(df[[i]])

for_cor=df.corr()
import seaborn as sns
sns.heatmap(for_cor, cmap="cool")

drp = ['fixed acidity', 'total sulfur dioxide']
df = df.drop(drp,axis=1)

from sklearn.model_selection import train_test_split
list_of_features=[]
for i in df:
  if i!="quality":
    list_of_features.append(i)
print(list_of_features)
x_data =  df[list_of_features]
y_data =  df['quality']
x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2,random_state=1)

# Import the dependencies for logistic regression
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

#Train the model
model = LogisticRegression()
model.fit(x_train, y_train) #Training the model
predictions = model.predict(x_test)
print(predictions)# printing predictions

logistic_accuracy = accuracy_score(y_test, predictions)
print(logistic_accuracy)

from warnings import WarningMessage
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
clf = DecisionTreeClassifier(criterion='entropy',random_state=1)
clf.fit(x_train,y_train)
y_pred = clf.predict(x_test)
score=accuracy_score(y_pred,y_test)
print(score)

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,0.5,1])
langs = ["Logistic Regression", "Decision Tree"]
students = [logistic_accuracy, score]
ax.bar(langs,students)
plt.show()